/**
 * @package umontreal.ssj.hups
 *
 * Highly Uniform Point Sets.
 *
 * ## Monte Carlo and quasi-Monte Carlo
 *
 * This package provides classes implementing *highly uniform point sets*
 * (HUPS) over the @f$s@f$-dimensional unit hypercube @f$[0,1)^s@f$, and
 * tools for their randomization. The terminology *low-discrepancy sequence*
 * (LDS) is often used for infinite sequences of points such that the
 * *discrepancy* between the distribution of the first @f$n@f$ points of the
 * sequence and the uniform distribution converges to zero at a certain rate
 * when @f$n\to\infty@f$ @cite rNIE92b&thinsp;. HUPS and LDS are used for
 * quasi-Monte Carlo integration, as we now briefly explain. See, e.g.,
 * @cite vFOX99a, @cite fGLA04a, @cite rHEL98a, @cite vLEC02a, @cite vLEC03b,
 * @cite vOWE98a, @cite rNIE92b, @cite vSLO94a, @cite rTEZ95a&thinsp; for
 * further details.
 *
 * Suppose we want to estimate the integral of a function @f$f@f$ defined
 * over the @f$s@f$-dimensional unit hypercube,
 * @anchor REF_hups_overview_eq_mu
 * @f[
 *   \mu= \int_{[0,1)^s}  f(\mathbf{u}) d\mathbf{u}. \tag{mu}
 * @f]
 * Practically any mathematical expectation that can be estimated by
 * simulation can be written in this way, usually for a very complicated
 * @f$f@f$ and sometimes for @f$s=\infty@f$. Indeed, the source of
 * randomness of stochastic simulations is usually a *stream* of real numbers
 * @f$\mathbf{u}= (u_0,u_1,u_2,…)@f$ whose purpose is to imitate i.i.d.
 * @f$U(0,1)@f$ random variables. These real numbers are transformed in
 * complicated ways to produce the estimator. Thus, the dimension @f$s@f$ of
 * the integral ( {@link REF_hups_overview_eq_mu mu} )
 * represents the number of calls to the uniform random number generator if
 * that number is deterministic. If it is random and unbounded, we take @f$s
 * = \infty@f$. In the latter case, however, we can assume that the *actual*
 * number of calls is finite with probability one (otherwise the simulation
 * may never end).
 *
 * We consider an estimator of @f$\mu@f$ of the form
 * @anchor REF_hups_overview_eq_Qn
 * @f[
 *   Q_n = \frac{1}{n} \sum_{i=0}^{n-1} f(\mathbf{u}_i), \tag{Qn}
 * @f]
 * which is the average of @f$f@f$ over the *point set* @f$P_n =
 * \{\mathbf{u}_0,…,\mathbf{u}_{n-1}\} \subset[0,1)^s@f$.
 *
 * With the *Monte Carlo* (MC) method, the @f$\mathbf{u}_i@f$’s are i.i.d.
 * random vectors uniformly distributed over @f$[0,1)^s@f$. Then, @f$Q_n@f$
 * is an unbiased estimator of @f$\mu@f$ with variance @f$\sigma^2/n@f$,
 * where
 * @f[
 *   \sigma^2 = \int_{[0,1)^s} f^2(\mathbf{u}) d\mathbf{u}- \mu^2,
 * @f]
 * and it obeys a central-limit theorem if @f$\sigma^2 < \infty@f$.
 *
 * *Quasi-Monte Carlo* (QMC) methods use point sets @f$P_n@f$ that are *more
 * evenly distributed* over the unit hypercube than typical random points. We
 * call them *highly uniform point sets* (HUPS). The aim is to reduce the
 * size of the integration error @f$Q_n - \mu@f$. Two important classes of
 * methods for constructing such point sets are *digital nets* and
 * *integration lattices* @cite rNIE92b, @cite vSLO94a, @cite vLEC02a,
 * @cite fGLA04a&thinsp;. Both are implemented in this package, in various
 * flavors.
 *
 * ## Elementary constructions
 *
 * To give an idea of how HUPS and LDS can be constructed, we start with a
 * simple one-dimensional example. If @f$s=1@f$ and @f$n@f$ is fixed, very
 * simple highly uniform constructions are the point sets @f$P_n = \{0,  1/n,
 * …, (n-1)/n\}@f$ and the shifted version @f$P’_n = \{1/(2n),  3/(2n),  …,
 * (2n-1)/(2n)\}@f$.
 *
 * In @f$s > 1@f$ dimensions, the simplest extensions would be as follows.
 * Let @f$n = d^s@f$ for some integer @f$d@f$ and define @f$P_n@f$ as the
 * Cartesian product of @f$s@f$ copies of the one-dimensional sets @f$P_d@f$;
 * that is, @f$P_n = \{(u_0,…,u_{s-1}) : u_j \in\{0,  1/d,  …, (d-1)/d\}@f$
 * for each @f$j\}@f$, and similarly for @f$P’_n@f$. The point sets thus
 * obtained are regular rectangular grids. Unfortunately, this approach
 * breaks down rapidly when @f$s@f$ gets large, because @f$n@f$ must increase
 * exponentially fast with @f$s@f$ for fixed @f$d@f$. Another important
 * drawback is that when @f$P_n@f$ is projected over lower-dimensional
 * subspaces, several points are projected onto each other and become
 * redundant @cite vLEC02a&thinsp;.
 *
 * A better idea is to construct a point set @f$P_n@f$ in @f$s@f$ dimensions
 * such that each one-dimensional projection of @f$P_n@f$ is the set of
 * values @f$\{0,  1/n,  …, (n-1)/n\}@f$. Of course, these values should not
 * be visited in the same order for all coordinates, because otherwise all
 * the points would lie on the diagonal line going from @f$(0,…,0)@f$ to
 * @f$(1,…,1)@f$. In other words, for each coordinate @f$j@f$, @f$0\le j <
 * s@f$, we must define a different *permutation* of the integers
 * @f$\{0,…,n-1\}@f$ and visit the values @f$\{0,  1/n,  …, (n-1)/n\}@f$ in
 * the order determined by that permutation. The trick is to select those
 * permutations in a way that @f$P_n@f$ itself is highly uniform over
 * @f$[0,1)^s@f$ in a well-defined sense (to be determined). This is what
 * most construction methods attempt to achieve. Before looking at concrete
 * ways of defining such permutations, we introduce a related issue: what to
 * do if @f$n@f$ is not fixed.
 *
 * For @f$s=1@f$, a simple way of filling up the unit interval @f$[0,1)@f$
 * uniformly is via the low-discrepancy sequence 0, 1/2, 1/4, 3/4, 1/8, 5/8,
 * 3/8, 7/8, 1/16, 9/16, …, called the *van der Corput sequence* in base 2.
 * More generally, select an integer @f$b \ge2@f$, called the *base*. The
 * *radical inverse* function in base @f$b@f$, @f$\psi_b :
 * \mathbb{N}\to[0,1)@f$, is defined as follows. If @f$i@f$ is a
 * @f$k@f$-digit integer in base @f$b@f$ with digital @f$b@f$-ary expansion
 * @f[
 *   i = a_0 + a_1 b + …+ a_{k-1} b^{k-1},
 * @f]
 * then
 * @f[
 *   \psi_b(i) = a_0 b^{-1} + a_1 b^{-2} + \cdots+ a_{k-1} b^{-k}.
 * @f]
 * For a given @f$b@f$, @f$\psi_b(0), \psi_b(1), \psi_b(2), …@f$ is called
 * the <em>van der Corput sequence in base @f$b@f$</em>. This sequence fills
 * up the unit interval @f$[0,1)@f$ quite uniformly. For example, for
 * @f$b=2@f$ we obtain the sequence mentioned above and for @f$b=3@f$ we
 * obtain 0, 1/3, 2/3, 1/9, 4/9, 7/9, 2/9, 5/9, 8/9, 1/27, 10/27, 19/27, ….
 * Moreover, for two relatively prime bases @f$b_1@f$ and @f$b_2@f$, the two
 * sequences have no value in common except 0.
 *
 * For @f$s > 1@f$, one could either take different (relatively prime) bases
 * for the different coordinates, or take the same basis @f$b@f$ but permute
 * the successive values using a different permutation for each coordinate.
 * These permutations are usually selected in a way that for every integer
 * @f$k@f$, the first @f$b^k@f$ values that are enumerated remain the same
 * (they are the values of @f$\psi_b(i)@f$ for @f$i=0,…,b^k-1@f$), but they
 * are enumerated in a different order. Several digital net constructions (to
 * be defined later) fit this framework.
 *
 * If we decide to take different bases, the most natural choice is to take
 * the @f$j@f$th smallest prime, @f$b_j@f$, as a base for coordinate
 * @f$j-1@f$; that is, base 2 for coordinate 0, base 3 for coordinate 1, base
 * 5 for coordinate 2, and so on. The infinite sequence thus defined, where
 * point @f$i@f$ is
 * @anchor REF_hups_overview_eq_Halton_point
 * @f[
 *   \mathbf{u}_i = (\psi_{b_1}(i),\psi_{b_2}(i),…, \psi_{b_s}(i)) \tag{Halton-point}
 * @f]
 * for @f$i \ge0@f$, was proposed in @cite rHAL60a&thinsp; and is called the
 * *Halton sequence*. One drawback of this sequence is that for large
 * @f$s@f$, the base @f$b_s@f$ becomes quite large.
 *
 * In the case where @f$n@f$ is fixed, we can always take @f$i/n@f$ as the
 * first coordinate of point @f$i@f$. In particular, the *Hammersley point
 * set* with @f$n@f$ points in @f$s@f$ dimensions contains the points
 * @anchor REF_hups_overview_eq_Hammersley_point
 * @f[
 *   \mathbf{u}_i = (i/n,\psi_{b_1}(i),\psi_{b_2}(i),…, \psi_{b_{s-1}}(i)), \tag{Hammersley-point}
 * @f]
 * for @f$i=0,…,n-1@f$ @cite rHAM60a&thinsp;. Historically, Halton sequences
 * were defined as extensions of Hammersley point sets.
 *
 * ## Digital nets
 *
 * *Digital nets and sequences* are an important class of HUPS and LDS
 * constructions. Most concrete implementations, e.g., those proposed by
 * Sobol’, Faure, Niederreiter, and Niederreiter and Xing, are *linear*
 * digital nets and sequences, defined as follows (see also @cite rNIE92b,
 * @cite rTEZ95a, @cite vLEC02a&thinsp;).
 *
 * Let @f$b\ge2@f$ be an arbitrary integer (usually a prime number), called
 * the *base*. A net that contains @f$n = b^k@f$ points in @f$s@f$ dimensions
 * is defined via @f$s@f$ *generator matrices*
 * @f$\mathbf{C}_0,…,\mathbf{C}_{s-1}@f$, which are (in theory)
 * @f$\infty\times k@f$ matrices whose elements are in @f$\mathbb{Z}_b =
 * \{0,…,b-1\}@f$. The matrix @f$\mathbf{C}_j@f$ is used for coordinate
 * @f$j@f$ of all the points, for @f$j\ge0@f$. To define the @f$i@f$th point
 * @f$\mathbf{u}_i@f$, for @f$i=0,…,b^k-1@f$, write the digital expansion of
 * @f$i@f$ in base @f$b@f$ and multiply the vector of its digits by
 * @f$\mathbf{C}_j@f$ to obtain the digits of the expansion of @f$u_{i,j}@f$,
 * the @f$j@f$th coordinate of @f$\mathbf{u}_i@f$. That is,
 * @anchor REF_hups_overview_eq_digital_i
 * @anchor REF_hups_overview_eq_digital_Cj
 * @anchor REF_hups_overview_eq_digital_uij
 * @anchor REF_hups_overview_eq_digital_ui
 * @f{align}{
 *    i 
 *    & 
 *   =
 *    \sum_{\ell=0}^{k-1} a_{i,\ell} b^{\ell}, \tag{digital-i} 
 *    \\ 
 *   \begin{pmatrix}
 *   u_{i,j,1}
 *    \\ 
 *   u_{i,j,2}
 *    \\ 
 *   \vdots
 *   \end{pmatrix}
 *    & 
 *   =
 *    \mathbf{C}_j 
 *   \begin{pmatrix}
 *   a_{i,0}
 *    \\ 
 *   a_{i,1}
 *    \\ 
 *   \vdots
 *    \\ 
 *   a_{i,k-1}
 *   \end{pmatrix}
 *   , \tag{digital-Cj} 
 *    \\ 
 *   u_{i,j} 
 *    & 
 *   =
 *    \sum_{\ell=1}^{\infty}u_{i,j,\ell} b^{-\ell}, \tag{digital-uij} 
 *    \\ 
 *   \mathbf{u}_i 
 *    & 
 *   =
 *    (u_{i,0},…,u_{i,s-1}). \tag{digital-ui}
 * @f}
 * In practice, the expansion in (
 * {@link REF_hups_overview_eq_digital_uij digital-uij} ) is
 * truncated to the first @f$r@f$ digits for some positive integer @f$r@f$,
 * so each matrix @f$\mathbf{C}_j@f$ is actually truncated to a
 * @f$r\times k@f$ matrix. Typically @f$r@f$ is equal to @f$k@f$, or is
 * slightly larger, or is selected so that @f$b^r@f$ is near @f$2^{31}@f$.
 *
 * Usually, the first @f$k@f$ lines of each @f$\mathbf{C}_j@f$ form a
 * nonsingular @f$k\times k@f$ matrix. Then, the @f$n@f$ output values for
 * coordinate @f$j@f$, @f$u_{0,j},…, u_{n-1,j}@f$, when truncated to their
 * first @f$k@f$ fractional digits in base @f$b@f$, are a permutation of the
 * numbers @f$0, 1/n, …, (n-1)/n@f$. Different coordinates simply use
 * different permutations, implemented via the matrices @f$\mathbf{C}_j@f$.
 *
 * When the first @f$k@f$ lines of @f$\mathbf{C}_j@f$ form the identity and
 * the other lines are zero, the first @f$n@f$ output values are the first
 * @f$n@f$ elements of the van der Corput sequence in base @f$b@f$. If we
 * reverse the order of the columns of that matrix @f$\mathbf{C}_j@f$ (i.e.,
 * column @f$c@f$ will contain a one in line @f$k-c+1@f$ and zeros elsewhere,
 * for @f$0\le c < k@f$), we obtain the output values @f$0, 1/n, …,
 * (n-1)/n@f$ in that order. With a slight abuse of language, we shall call
 * this first matrix (with the identity followed by lines of zeros) the
 * *identity* and the second one (with the columns in reverse order) the
 * *reflected identity*. It is customary to take @f$\mathbf{C}_0@f$ as the
 * identity for digital sequences, and often for digital nets as well. But
 * for digital nets (where @f$n@f$ is fixed in advance), one can take
 * @f$\mathbf{C}_0@f$ as the reflected identity instead, then
 * @f$\mathbf{C}_1@f$ as the identity, and so on. That is, the matrix
 * @f$\mathbf{C}_j@f$ for the digital net is taken as the matrix
 * @f$\mathbf{C}_{j-1}@f$ of the digital sequence. Our package often gives
 * the choice.
 *
 * For digital sequences, the matrices @f$\mathbf{C}_j@f$ actually have an
 * infinite number of columns, although only the first @f$k@f$ columns are
 * needed to generate the first @f$b^k@f$ points. So in practice, we never
 * need to store more than a finite number of columns at a time. Whenever we
 * find that we need more than @f$b^k@f$ points for the current value of
 * @f$k@f$, we can simply increase @f$k@f$ and add the corresponding columns
 * to the matrices @f$\mathbf{C}_j@f$.
 *
 * The classes  @ref umontreal.ssj.hups.DigitalNet and
 * @ref umontreal.ssj.hups.DigitalSequence implement generic digital nets and
 * sequences. Specific instances are constructed in subclasses of these two
 * classes.
 *
 * ## Lattice Rules
 *
 * An *integration lattice* is a discrete (but infinite) subset of
 * @f$\mathbb{R}^s@f$ of the form
 * @f[
 *   L_s = \left\{\mathbf{v}= \sum_{j=1}^s h_j {\mathbf{v}_j} \mbox{ such that each } h_j\in\mathbb{Z}\right\},
 * @f]
 * where @f$\mathbf{v}_1,…,\mathbf{v}_s \in\mathbb{R}^s@f$ are linearly
 * independent over @f$\mathbb{R}@f$ and @f$\mathbb{Z}^s \subseteq L_s@f$.
 * This last condition means that @f$L_s@f$ must contain all integer vectors,
 * and this implies that @f$L_s@f$ is periodic with period 1 along each of
 * the @f$s@f$ coordinates. The approximation of @f$\mu@f$ by @f$Q_n@f$ with
 * the point set @f$P_n = L_s \cap[0,1)^s@f$ is called a *lattice rule*
 * @cite mKOR59a, @cite vSLO94a&thinsp;. The value of @f$n@f$ is the number
 * of points of the lattice that are in the unit hypercube @f$[0,1)^s@f$.
 *
 * Let @f$\mathbf{V}@f$ be the matrix whose rows are the basis vectors
 * @f$\mathbf{v}_1,\cdots,\mathbf{v}_s@f$ and @f$\mathbf{V}^{-1}@f$ its
 * inverse. One has @f$\mathbb{Z}^s\subseteq L_s@f$ if and only if all
 * entries of @f$\mathbf{V}^{-1}@f$ are integer. When this holds, @f$n =
 * \det(\mathbf{V}^{-1})@f$ and all entries of @f$\mathbf{V}@f$ are
 * multiples of @f$1/n@f$.
 *
 * The *rank* of the lattice is the smallest @f$r@f$ such that one can find a
 * basis of the form @f$\mathbf{v}_1,…,
 * \mathbf{v}_r,\mathbf{e}_{r+1},\cdots,\mathbf{e}_s@f$, where
 * @f$\mathbf{e}_j@f$ is the @f$j@f$th unit vector in @f$s@f$ dimensions. In
 * particular, a lattice rule of *rank 1* has a basis of the form
 * @f$\mathbf{v}_1 = (a_1, …, a_s)/n@f$ and @f$\mathbf{v}_j = \mathbf{e}_j@f$
 * for @f$j>1@f$, where @f$a_j \in\mathbb{Z}_n@f$ for each @f$j@f$. It is a
 * *Korobov* rule if @f$\mathbf{v}_1@f$ has the special form @f$\mathbf{v}_1
 * = (1,\; a,\; a^2 \mod n,\; …,\; a^{s-1} \mod n)/n@f$ for some
 * @f$a\in\mathbb{Z}_n@f$. The point set @f$P_n@f$ of a Korobov lattice rule
 * can also be written as @f$P_n = \{(x_1,…,x_s)/n \mbox{ such that }
 * x_1\in\mathbb{Z}_n \mbox{ and } x_j = a x_{j-1} \mod n \mbox{ for all } j
 * > 1\}@f$. This is the set of all vectors of successive values produced by
 * a linear congruential generator (LCG) with modulus @f$n@f$ and multiplier
 * @f$a@f$, from all possible initial states, including 0. In this case, the
 * points are easy to enumerate by using the recurrence.
 *
 * ## Cycle-based point sets
 *
 * Certain types of point sets are defined pretty much like random number
 * generators: choose a finite state space @f$\mathcal{S}@f$, a transition
 * function @f$f : \mathcal{S}\to\mathcal{S}@f$, an output function @f$g :
 * \mathcal{S}\to[0,1)@f$, and define
 * @f[
 *   P_n = \{\mathbf{u}= (u_0,u_1,…) : s_0\in\mathcal{S}, s_j = f(s_{j-1}), \mbox{ and } u_j = g(s_j) \mbox{ for all } j\}.
 * @f]
 * This is the set of all vectors of successive output values produced by the
 * recurrence defined by @f$f@f$ and the output function @f$g@f$, from all
 * possible initial states. The value of @f$n@f$ is the cardinality of
 * @f$\mathcal{S}@f$ and the dimension @f$s@f$ is infinite. We could also
 * have @f$n = \infty@f$ (an infinite sequence) if @f$\mathcal{S}@f$ is
 * infinite but denumerable and ordered (so we know in which order to
 * enumerate the points).
 *
 * Let us assume that @f$n@f$ is finite and that for each
 * @f$s_0\in\mathcal{S}@f$, the recurrence @f$s_j = f(s_{j-1})@f$ is *purely
 * periodic*, i.e., there is always an integer @f$j@f$ such that @f$s_j =
 * s_0@f$. The smallest such @f$j@f$, called the *period length*, depends in
 * general on @f$s_0@f$. Thus, the state space @f$\mathcal{S}@f$ is
 * partitioned into a finite number of *cycles*. The successive coordinates
 * of any point @f$\mathbf{u}\in P_n@f$ are periodic with period length equal
 * to the length of the cycle that contains @f$s_0@f$ (and the following
 * @f$s_j@f$’s).
 *
 * One way of implementing such a point set while avoiding to recompute
 * @f$f@f$ and @f$g@f$ each time a coordinate is needed is to store
 * explicitly all the cycles of the recurrence, in the form of a *list of
 * cycles*. We can store either the successive @f$u_j@f$’s directly, or the
 * successive @f$s_j@f$’s, over each cycle. The class
 * @ref umontreal.ssj.hups.CycleBasedPointSet provides the framework for
 * doing that.
 *
 * For example, a Korobov lattice point set is defined via the recurrence
 * @f$x_j = a x_{j-1} \mod n@f$ and output function @f$u_j = x_j/n@f$. If
 * @f$n@f$ is prime and @f$a@f$ is a primitive element modulo @f$n@f$, then
 * there are two cycles: one of period 1 that contains only 0, and the other
 * of period @f$n-1@f$. For more general @f$n@f$ and @f$a@f$, there will be
 * more cycles. The class  @ref umontreal.ssj.hups.LCGPointSet constructs
 * this type of point set and stores explicitly the successive values of
 * @f$u_j@f$ over the different cycles.
 *
 * There are cases where @f$n@f$ is a power of two, say @f$n = 2^k@f$, and
 * where the state @f$s_j@f$ is represented as a @f$k@f$-bit string. In that
 * context, it is often more convenient to store the successive @f$s_j@f$’s
 * instead of the successive @f$u_j@f$’s, over the set of cycles (e.g., if a
 * random digital shift in base 2 is to be applied to randomize the points,
 * it can be performed by applying a bitwise xor directly to @f$s_j@f$). When
 * generating the coordinates, the @f$s_j@f$’s can be interpreted as
 * @f$2^k@f$-bit integers and multiplied by @f$2^{-k}@f$ to produce the
 * output. This is supported by the class
 * @ref umontreal.ssj.hups.CycleBasedPointSetBase2. Special instances of this
 * class are usually based on linear recurrences modulo 2 and they include
 * the Korobov-type *polynomial lattice rules* @cite rLEC99a, @cite vLEC99a,
 * @cite rLEC02b, @cite vLEM03a, @cite rPAN04a&thinsp;.
 *
 * ## Randomized quasi-Monte Carlo
 *
 * In their original versions, these HUPS are deterministic, and the
 * corresponding QMC methods give a *deterministic* integration error that is
 * difficult to estimate. In *randomized* QMC methods, @f$P_n@f$ is
 * randomized, preferably in a way that it retains its high uniformity over
 * @f$[0,1)^s@f$ when taken as a set, while each of its points has the
 * uniform distribution over @f$[0,1)^s@f$ when taken individually. Then,
 * @f$Q_n@f$ becomes an unbiased estimator of @f$\mu@f$, hopefully with
 * smaller variance than the standard MC estimator. To estimate the variance
 * and compute a confidence interval on @f$\mu@f$, one can apply @f$m@f$
 * independent randomizations to the same @f$P_n@f$, and compute
 * @f${\bar{X}_m}@f$ and @f${S_{m,x}^2}@f$, the sample mean and sample
 * variance of the @f$m@f$ corresponding (independent) copies of @f$Q_n@f$.
 * Then, @f$E[\bar{X}_m] = \mu@f$ and @f$E[S_{m,x}^2] = \mathrm{Var}[Q_n] =
 * m\mathrm{Var}[\bar{X}_m]@f$ @cite vLEC00b&thinsp;.
 *
 * Two examples of such randomizations are the *random shift modulo 1*,
 * proposed in @cite vCRA76a&thinsp; and implemented in class
 * @ref umontreal.ssj.hups.RandShiftedPointSet, and the <em>random digital
 * shift in base @f$b@f$</em>, described and implemented in class
 * @ref umontreal.ssj.hups.DigitalNet. These randomizations are also
 * incorporated directly in certain types of point sets such as
 * @ref umontreal.ssj.hups.CycleBasedPointSet,
 * @ref umontreal.ssj.hups.CycleBasedPointSetBase2, etc.
 *
 * In the random shift modulo 1, we generate a *single* point
 * @f$\mathbf{u}@f$ uniformly over @f$[0,1)^s@f$ and add it to each point of
 * @f$P_n@f$, coordinate-wise, modulo 1. Since all points of @f$P_n@f$ are
 * shifted by the same amount, the set retains most of its structure and
 * uniformity.
 *
 * For the random digital shift in base @f$b@f$, we generate again a single
 * @f$\mathbf{u}= (u_1,…,u_s)@f$ uniformly over @f$[0,1)^s@f$, write the
 * digital expansion in base @f$b@f$ of each of its coordinates, say @f$u_j =
 * \sum_{\ell=1}^{\infty}d_{j,\ell} b^{-\ell}@f$, then add
 * @f$d_{j,\ell}@f$ modulo @f$b@f$ to the @f$\ell@f$th digit of the digital
 * expansion in base @f$b@f$ of the @f$j@f$th coordinate of each point
 * @f$\mathbf{u}_i\in P_n@f$. For @f$b=2@f$, the digit-wise addition modulo
 * @f$b@f$ becomes a bitwise exclusive-or, which is fast to perform on a
 * computer.
 *
 * An interesting property of the digital shift in base @f$b@f$ is that if
 * the hypercube @f$[0,1)^s@f$ is partitioned into @f$b^{q_1 + \cdots+
 * q_s}@f$ rectangular boxes of the same size by partitioning the @f$j@f$th
 * axis into @f$b^{q_j}@f$ equal parts for each @f$j@f$, for some integers
 * @f$q_j \ge0@f$ (such a partition is called a
 * <em>@f$\mathbf{q}@f$-equidissection in base @f$b@f$</em> of the unit
 * hypercube, where @f$\mathbf{q}= (q_1,…,q_s)@f$), then the number of boxes
 * that contain @f$m@f$ points, for each integer @f$m@f$, is unchanged by the
 * randomization. In particular, if each box contains the same number of
 * points of @f$P_n@f$ before the randomization, then it also does after the
 * randomization. In this case, we say that @f$P_n@f$ is
 * <em>@f$\mathbf{q}@f$-equidistributed in base @f$b@f$</em>. Several other
 * randomization methods exist and most are adapted to special types of point
 * sets; see, e.g.,  @ref umontreal.ssj.hups.DigitalNet and
 * @cite vOWE03a&thinsp;.
 *
 * ## Point set implementations and enumeration tools
 *
 * Let @f$\mathbf{u}_i = (u_{i,0}, u_{i,1}, …, u_{i,s-1})@f$ be the elements
 * of the point set @f$P_n@f$, for @f$i=0,…,n-1@f$. Both the number of points
 * @f$n@f$ and the dimension @f$s@f$ can be finite or infinite. The point set
 * can be viewed as a two-dimensional array whose element @f$(i,j)@f$
 * contains @f$u_{i,j}@f$, the coordinate @f$j@f$ of point @f$i@f$. In the
 * implementations of typical point sets, the values @f$u_{i,j}@f$ are not
 * stored explicitly in a two-dimensional array, but pertinent information is
 * organized so that the points and their coordinates can be generated
 * efficiently. The base class for point sets is the abstract class
 * @ref umontreal.ssj.hups.PointSet.
 *
 * To enumerate the successive points or the successive coordinates of a
 * given point, we use *point set iterators*, which resemble the iterators
 * defined in Java *collections*, except that they loop over bi-dimensional
 * sets. Their general behavior is defined in the interface
 * @ref umontreal.ssj.hups.PointSetIterator. Several independent iterators
 * can coexist at any given time for the same point set. Each one maintains a
 * current point index and a current coordinate index, which are incremented
 * by one when the iterator advances to the next point or the next
 * coordinate. Both are initialized to 0. Each subclass of
 * @ref umontreal.ssj.hups.PointSet has its own implementation of
 * @ref umontreal.ssj.hups.PointSetIterator and has a method `iterator` that
 * creates and returns a new point set iterator of the correct type.
 *
 * An important feature of the  @ref umontreal.ssj.hups.PointSetIterator
 * interface is that it extends the  @ref umontreal.ssj.rng.RandomStream
 * interface. This means that any point set iterator can be used in place of
 * a random stream that is supposed to generate i.i.d. @f$U(0,1)@f$ random
 * variables, anywhere in a simulation program. It then becomes very easy to
 * replace the (pseudo)random numbers by the coordinates @f$u_{i,j}@f$ of a
 * randomized HUPS without changing the internal code of the simulation
 * program.
 *
 * ## Transformed point sets and containers
 *
 * HUPS are often transformed either deterministically or randomly.
 * Deterministic transformations can be applied to improve the uniformity, or
 * to eliminate some points or coordinates (i.e., selecting subsets), or to
 * concatenate point sets (padding), or to take an antithetic version of a
 * point set, etc. Random transformations are used for randomized QMC. They
 * are also useful when the *average* of a uniformity measure of interest
 * over the outcomes of a certain type of randomization is much better than
 * the worst case and may be better than the uniformity measure of the
 * original point set. When a point set is transformed, we often want to keep
 * the original as well, and we may want to apply different types of
 * transformations or different independent randomizations to the same point
 * set.
 *
 * This can be achieved via *container* point sets, which are defined in
 * terms of another point set to which they keep a reference and apply
 * certain transformations.  @ref umontreal.ssj.hups.ContainerPointSet is the
 * base class for such containers. One example is
 * @ref umontreal.ssj.hups.RandShiftedPointSet, which applies a random shift
 * modulo 1 to the point set that it contains. Of course, the contained point
 * set can be a container itself and this can be done recursively, but too
 * many levels of recursiveness may impair the performance (speed).
 *
 * ## Examples
 *
 * To be done...
 *
 * ## Steps for performing Quasi-Monte Carlo simulation
 *
 * <ol><li>
 * Decide which type of point set will be used and create it by constructing
 * a subclass of  @ref umontreal.ssj.hups.PointSet.
 * </li>
 * <li>
 * Get an iterator for the point set and use it as an ordinary random number
 * stream. It can be used to create non-uniform random number generators as
 * well, although only inversion should be used.
 * </li>
 * <li>
 * For each of the @f$R@f$ replications of the simulation, do the following
 * to compute the statistic @f$x_r@f$, for @f$r=0,…,R-1@f$.
 *
 * <ol><li>
 * Randomize the point set using a uniform x1random number stream.
 * </li>
 * <li>
 * Perform @f$n@f$ replications of the simulation, each with a different
 * point in the point set. For each replication, one should obtain the result
 * @f$x_{r,i}@f$, where @f$i=0,…,n-1@f$.
 *
 * Note: All the points from a finite point set should be used to fully take
 * advantage of its low discrepancy.
 * </li>
 * <li>
 * Compute the statistic
 * @f[
 *   x_r=\frac{1}{n}\sum_{i=0}^{n-1} x_{r,i}.
 * @f]
 * </li>
 * <li>
 * Reset the point set iterator for the next replication.
 * </li>
 * </ol>
 * </li>
 * <li>
 * The values @f$x_0,…,x_{r-1}@f$ can be used as statistical observations to
 * compute the @f$\bar{x}@f$ estimator, confidence interval, ...
 * </li>
 * </ol>
 *
 * ## Representation of a point set
 *
 * The (abstract) base class  @ref umontreal.ssj.hups.PointSet views a *point
 * set* as a set of @f$n@f$ points in the @f$t@f$-dimensional unit hypercube
 * @f$[0,1)^t@f$. A point set can also be viewed (and stored) as an
 * @f$n\times t@f$ matrix whose element @f$(i,j)@f$ is the @f$j@f$th
 * coordinate of the @f$i@f$th point, for @f$0\le i < n@f$ and @f$0\le j <
 * t@f$ (both the point and coordinate indexes start from zero). One can
 * directly use methods of this class, but this is sometimes not the most
 * efficient technique for accessing coordinates of a point set and it
 * results in two versions of the same simulation application, one for Monte
 * Carlo and another one for Quasi-Monte Carlo. The class contains a method
 * allowing one to construct a *point set iterator* which can traverse the
 * point set more efficiently.
 *
 * The  @ref umontreal.ssj.hups.PointSetIterator contains all needed methods
 * to traverse a point set. One can return only one coordinate, @f$t@f$
 * coordinates, change the current coordinate and current point index, reset
 * the iterator, ... Since the class implements
 * @ref umontreal.ssj.rng.RandomStream, it can be used exactly as a uniform
 * random number generator. This allows one to use the same application logic
 * for MC and QMC simulation; only the initialization part will depend on the
 * type of simulation. Every point set implements its own specialized
 * iterator, allowing an efficient access to the coordinates.
 *
 * ## Supported types of point sets
 *
 * The `hups` package supports several types of point sets implemented in
 * different classes extending  @ref umontreal.ssj.hups.PointSet. The
 * @ref umontreal.ssj.hups.CycleBasedPointSet class provides the needed basis
 * for implementing cycle-based point sets. Each point is obtained by an
 * initial value which lies in a given cycle. The coordinates are obtained by
 * visiting all the points of the given cycle periodically, so the point set
 * has an infinite dimension. The  @ref umontreal.ssj.hups.LCGPointSet is an
 * implementation of a cycle-based point set whose cycles are generated using
 * a small LCG. Such a point set corresponds to a Korobov lattice rule.
 *
 * Generic rank 1 lattices rules are implemented in the class
 * @ref umontreal.ssj.hups.Rank1Lattice. Korobov lattice sequences are
 * implemented in the class  @ref umontreal.ssj.hups.KorobovLatticeSequence.
 *
 * Two types of digital nets are supported, namely base-2 and base-@f$b@f$.
 * They are implemented in separate base class because some optimizations can
 * be done for the special case of base&nbsp;2. The
 * @ref umontreal.ssj.hups.DigitalNetBase2 class, which implements digital
 * nets in base 2, provides all required facilities for computing points from
 * such a digital net. It also supports scrambling as randomization. A
 * digital net implementation needs to provide the adequate generating
 * matrices to the base class. Sobol, Niederreiter and Niederreiter-Xing
 * sequences are supported in base&nbsp;2.
 *
 * The class  @ref umontreal.ssj.hups.DigitalNet provides the required
 * facilities for implementing digital nets in an arbitrary base @f$b@f$. For
 * now, the only supported digital net in base @f$b > 2@f$ is the Faure
 * sequence.
 *
 * Some supported point sets are nor lattice rules, nor digital nets. The
 * Halton sequence and Hammersley net are ancestors of linear digital nets
 * and sequences and they are implemented in ordinary and scrambled forms.
 *
 * ## Randomization and container point sets
 *
 * Randomization can be performed in two ways. The interface
 * @ref umontreal.ssj.hups.Randomization is used to specify randomizations
 * transforming the structure of the point set, for example scrambling in the
 * case of digital nets. The class  @ref umontreal.ssj.hups.PointSet contains
 * an internal list of randomizations that will be applied sequentially when
 * calling the method  umontreal.ssj.hups.PointSet.randomize. The method
 * umontreal.ssj.hups.PointSet.unrandomize restores the point set to its
 * original, deterministic, structure. Other randomizations act somewhat like
 * a filter and are implemented as container point sets. For example, the
 * class  @ref umontreal.ssj.hups.RandShiftedPointSet represents a point set
 * whose coordinates are shifted modulo 1 with a random factor. This shift is
 * applied after the contained point set generates its coordinates and it can
 * be applied to any point set.
 *
 * The package uses container point set for other purposes than
 * randomization. The class  @ref umontreal.ssj.hups.CachedPointSet can be
 * used to store the coordinates of a point set. It is then stored internally
 * as a matrix and can be accessed very efficiently. The
 * @ref umontreal.ssj.hups.SubsetOfPointSet allows one to constrain a point
 * set’s size or dimension, for example to get the dimension of a cycle-based
 * point set finite. The class  @ref umontreal.ssj.hups.PaddedPointSet
 * gathers some coordinates of several point sets to construct a padded point
 * set. The class  @ref umontreal.ssj.hups.AntitheticPointSet allows one to
 * switch on or off the antithetic coordinates generation.
 *
 * Such container point sets implement their own iterators that use the
 * iterators of the contained point sets to access the points almost as
 * efficiently as if the contained point set iterators were used directly.
 */